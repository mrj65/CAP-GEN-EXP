{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install gradio diffusers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T21:55:23.597736Z","iopub.execute_input":"2025-01-24T21:55:23.597953Z","iopub.status.idle":"2025-01-24T21:55:41.669575Z","shell.execute_reply.started":"2025-01-24T21:55:23.597929Z","shell.execute_reply":"2025-01-24T21:55:41.668649Z"}},"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-5.13.1-py3-none-any.whl.metadata (16 kB)\nCollecting diffusers\n  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.4.0)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.6.0 (from gradio)\n  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.25.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.26.2)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\nRequirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.3.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.1)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.2)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.13.2)\nRequirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.3)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.30.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.6.0->gradio) (2024.6.0)\nRequirement already satisfied: websockets<15.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.6.0->gradio) (12.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (7.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.15.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.5)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->gradio) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.27.1)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.19.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.13.1-py3-none-any.whl (57.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nInstalling collected packages: semantic-version, ruff, python-multipart, ffmpy, starlette, safehttpx, gradio-client, fastapi, diffusers, gradio\n  Attempting uninstall: python-multipart\n    Found existing installation: python-multipart 0.0.9\n    Uninstalling python-multipart-0.0.9:\n      Successfully uninstalled python-multipart-0.0.9\n  Attempting uninstall: starlette\n    Found existing installation: starlette 0.37.2\n    Uninstalling starlette-0.37.2:\n      Successfully uninstalled starlette-0.37.2\n  Attempting uninstall: fastapi\n    Found existing installation: fastapi 0.111.0\n    Uninstalling fastapi-0.111.0:\n      Successfully uninstalled fastapi-0.111.0\nSuccessfully installed diffusers-0.32.2 fastapi-0.115.7 ffmpy-0.5.0 gradio-5.13.1 gradio-client-1.6.0 python-multipart-0.0.20 ruff-0.9.3 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import gradio as gr\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport torch\nfrom transformers import BlipProcessor, BlipForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM\nimport io\nfrom diffusers import StableDiffusionPipeline","metadata":{"_uuid":"a0d05577-c057-4cd9-a678-5a7ded4d9af8","_cell_guid":"1e80e40e-9bb1-4ba2-b14b-e5bc41232251","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-24T21:55:41.672257Z","iopub.execute_input":"2025-01-24T21:55:41.672678Z","iopub.status.idle":"2025-01-24T21:56:04.923723Z","shell.execute_reply.started":"2025-01-24T21:55:41.672635Z","shell.execute_reply":"2025-01-24T21:56:04.923036Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load BLIP model and processor\nmodel_name = \"Salesforce/blip-image-captioning-large\"\nblip_processor = BlipProcessor.from_pretrained(model_name)\nblip_model = BlipForConditionalGeneration.from_pretrained(model_name).to(device)\nblip_model.config.vision_config.output_attentions = True\n\n# Load Stable Diffusion model\ndiffusion_model_name = \"CompVis/stable-diffusion-v1-4\"\ndiffusion_pipeline = StableDiffusionPipeline.from_pretrained(diffusion_model_name).to(device)\n\n# Load smol model\nsmol_model_name = \"Michaelj1/INSTRUCT_smolLM2-360M-finetuned-wikitext2-raw-v1\"\ntokenizer = AutoTokenizer.from_pretrained(smol_model_name)\nsmol_model = AutoModelForCausalLM.from_pretrained(smol_model_name).to(device)","metadata":{"_uuid":"a0d05577-c057-4cd9-a678-5a7ded4d9af8","_cell_guid":"1e80e40e-9bb1-4ba2-b14b-e5bc41232251","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-24T21:56:04.924856Z","iopub.execute_input":"2025-01-24T21:56:04.926002Z","iopub.status.idle":"2025-01-24T21:57:14.094260Z","shell.execute_reply.started":"2025-01-24T21:56:04.925953Z","shell.execute_reply":"2025-01-24T21:57:14.093543Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"233164752d784b8a88864fb100ee6a4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/527 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c339a497fd8481d9bc5e1a6c9a16d46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"213995afb4d74b4b93c20fe399bdb512"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73750ba20ca8411cb700d09d1706dde8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e137b4f2354c4f5db384a7f0a8aae1eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7814d6861b84642870499e3cd7678a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c59361a98aed482fbebdf404afbbe6ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d353a534d3e4c9e8c4cba1a1f413e34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03490f74f8fe45a18e6186923cea3d71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"safety_checker/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"904cf1768f574f75a425b59e9e97b756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)kpoints/scheduler_config-checkpoint.json:   0%|          | 0.00/209 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8dc5e1f35ed49839847852de520f993"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da60acd95add477dad04904eed6dcae0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"253b33f3cf6149d988f546557ffb6eaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a0a0bdcabfc483b9f3dcf3efba7d14b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d32d31c9952f477ba55147dd4a75c859"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0684cb40b81c43f5a4d8db512fb91e04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler/scheduler_config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be47161238614a0092b36948bbce8a39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6b87bffc6e64eec9f917bd798efe786"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"424590aabfda425fa1708000ff534499"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f912d99b98e44d5ca278b8ef56560cc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f134f368bc244772a84abb6b3c75ab68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a05b672da578451ab8cfba4f31fd104b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/config.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ba953cce94242089094f3210eb90ed9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2fee7710cfe4f8a9d21f1c215772176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfd5536591b543a088157f843ed80121"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69666ee9378544fca0763c5c13f3fcc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0616244a9e834f38b3539d8eaf98eb68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2652781753764d1881ea4686e2a222b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b867476bfeb49c986c5434260ee3e45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/541 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27c604a7158b44528a5ac869969eb782"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/921 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ef0e101b1794eb193723302b9ec3292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.45G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c997c703d7c143e6b83bb81b58044a51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4b8f59c3ac41b08e1d7c011c03d734"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def generate_caption(image):\n    inputs = blip_processor(images=image, return_tensors=\"pt\").to(device)\n    caption_ids = blip_model.generate(**inputs, max_new_tokens=50)\n    caption = blip_processor.decode(caption_ids[0], skip_special_tokens=True)\n    return caption, inputs\n\ndef generate_gradcam(image, inputs):\n    with torch.no_grad():\n        vision_outputs = blip_model.vision_model(**inputs)\n        attentions = vision_outputs.attentions\n    last_layer_attentions = attentions[-1]\n    avg_attention = last_layer_attentions.mean(dim=1)\n    cls_attention = avg_attention[:, 0, 1:]\n    num_patches = cls_attention.shape[-1]\n    grid_size = int(np.sqrt(num_patches))\n    attention_map = cls_attention.cpu().numpy().reshape(grid_size, grid_size)\n    attention_map = cv2.resize(attention_map, (image.size[0], image.size[1]))\n    attention_map = attention_map - np.min(attention_map)\n    attention_map = attention_map / np.max(attention_map)\n    img_np = np.array(image)\n    heatmap = cv2.applyColorMap(np.uint8(255 * attention_map), cv2.COLORMAP_JET)\n    heatmap = np.float32(heatmap) / 255\n    cam = heatmap + np.float32(img_np) / 255\n    cam = cam / np.max(cam)\n    cam_image = np.uint8(255 * cam)\n    return cam_image\n\n\ndef generate_image_from_caption(caption):\n    image = diffusion_pipeline(caption).images[0]\n    return image\n\n\ndef explain_word(word):\n    messages = [{\"role\": \"user\", \"content\": f\"Explain the word '{word}' in detail.\"}]\n    input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n    outputs = smol_model.generate(\n        inputs,\n        max_new_tokens=150,\n        temperature=0.9,\n        top_p=0.95,\n        do_sample=True\n    )\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    lines = generated_text.split('\\n')\n    assistant_response = []\n    collect = False\n    for line in lines:\n        line = line.strip()\n        if line.lower() == 'assistant':\n            collect = True\n            continue\n        elif line.lower() in ['system', 'user']:\n            collect = False\n        if collect and line:\n            assistant_response.append(line)\n    explanation = '\\n'.join(assistant_response).strip()\n    return explanation\n\ndef get_caption_self_attention(caption):\n    text_inputs = blip_processor.tokenizer(\n        caption,\n        return_tensors=\"pt\",\n        add_special_tokens=True\n    ).to(device)\n    \n    with torch.no_grad():\n        outputs = blip_model.text_decoder(\n            input_ids=text_inputs.input_ids,\n            attention_mask=text_inputs.attention_mask,\n            output_attentions=True,\n            return_dict=True,\n        )\n    decoder_attentions = outputs.attentions\n    return decoder_attentions, text_inputs\n\n\ndef generate_self_attention(decoder_attentions, text_inputs):\n    last_layer_attentions = decoder_attentions[-1]\n    avg_attentions = last_layer_attentions.mean(dim=1)\n    attentions = avg_attentions[0].cpu().numpy()\n    tokens = blip_processor.tokenizer.convert_ids_to_tokens(text_inputs.input_ids[0])\n    cls_token = blip_processor.tokenizer.cls_token or \"[CLS]\"\n    sep_token = blip_processor.tokenizer.sep_token or \"[SEP]\"\n    special_token_indices = [idx for idx, token in enumerate(tokens) if token in [cls_token, sep_token]]\n    mask = np.ones(len(tokens), dtype=bool)\n    mask[special_token_indices] = False\n    filtered_tokens = [token for idx, token in enumerate(tokens) if mask[idx]]\n    filtered_attentions = attentions[mask, :][:, mask]\n    return filtered_tokens, filtered_attentions\n\ndef process_image(image):\n    # Ensure input is in the correct format\n    if isinstance(image, np.ndarray):\n        image = Image.fromarray(image)\n    caption, inputs = generate_caption(image)\n    cam_image = generate_gradcam(image, inputs)\n    diffusion_image = generate_image_from_caption(caption)\n    decoder_attentions, text_inputs = get_caption_self_attention(caption)\n    filtered_tokens, filtered_attentions = generate_self_attention(decoder_attentions, text_inputs)\n    \n    # Create visualization grid\n    fig, axs = plt.subplots(2, 2, figsize=(9, 9))\n    \n    axs[0][0].imshow(image)\n    axs[0][0].axis('off')\n    axs[0][0].set_title('Original Image')\n    \n    axs[0][1].imshow(cam_image)\n    axs[0][1].axis('off')\n    axs[0][1].set_title('Grad-CAM Overlay')\n    \n    axs[1][0].imshow(diffusion_image)\n    axs[1][0].axis('off')\n    axs[1][0].set_title('Generated Image (Stable Diffusion)')\n    \n    ax = axs[1][1]\n    im = ax.imshow(filtered_attentions, cmap='viridis')\n    ax.set_xticks(range(len(filtered_tokens)))\n    ax.set_yticks(range(len(filtered_tokens)))\n    ax.set_xticklabels(filtered_tokens, rotation=90, fontsize=8)\n    ax.set_yticklabels(filtered_tokens, fontsize=8)\n    ax.set_title('Caption Self-Attention')\n    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n    \n    plt.tight_layout()\n    \n    # Save visualization to a buffer for display\n    buffer = io.BytesIO()\n    plt.savefig(buffer, format='png')\n    plt.close(fig)\n    buffer.seek(0)\n    visualization_image = Image.open(buffer)\n    \n    # Generate word options for dropdown\n    words = caption.split()\n    return caption, visualization_image, gr.Dropdown(label=\"Select a Word from Caption\", choices=words, interactive=True)\n\n\ndef get_word_explanation(word):\n    explanation = explain_word(word)\n    return f\"Explanation for '{word}':\\n\\n{explanation}\"","metadata":{"_uuid":"a0d05577-c057-4cd9-a678-5a7ded4d9af8","_cell_guid":"1e80e40e-9bb1-4ba2-b14b-e5bc41232251","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-24T21:59:17.888878Z","iopub.execute_input":"2025-01-24T21:59:17.889233Z","iopub.status.idle":"2025-01-24T21:59:17.908301Z","shell.execute_reply.started":"2025-01-24T21:59:17.889202Z","shell.execute_reply":"2025-01-24T21:59:17.907312Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Define Gradio interface\nwith gr.Blocks() as interface:\n    gr.Markdown(\"# Image Captioning and Visualization with Word Explanation\")\n    \n    with gr.Row():\n        with gr.Column():\n            image_input = gr.Image(type=\"pil\", label=\"Upload an Image\")\n            process_button = gr.Button(\"Process Image\")\n        with gr.Column():\n            caption_output = gr.Textbox(label=\"Generated Caption\")\n            visualization_output = gr.Image(type=\"pil\", label=\"Visualization (Original, Grad-CAM, Stable Diffusion)\")\n    \n    word_dropdown = gr.Dropdown(label=\"Select a Word from Caption\", choices=[], interactive=True)\n    word_explanation = gr.Textbox(label=\"Word Explanation\")\n    \n    # Bind functions to components\n    process_button.click(\n        process_image,\n        inputs=image_input,\n        outputs=[caption_output, visualization_output, word_dropdown]\n    )\n    \n    word_dropdown.change(\n        get_word_explanation,\n        inputs=word_dropdown,\n        outputs=word_explanation\n    )","metadata":{"_uuid":"a0d05577-c057-4cd9-a678-5a7ded4d9af8","_cell_guid":"1e80e40e-9bb1-4ba2-b14b-e5bc41232251","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-24T21:59:30.864654Z","iopub.execute_input":"2025-01-24T21:59:30.865108Z","iopub.status.idle":"2025-01-24T21:59:31.085519Z","shell.execute_reply.started":"2025-01-24T21:59:30.865066Z","shell.execute_reply":"2025-01-24T21:59:31.084864Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"app = interface.launch()\n","metadata":{"_uuid":"a0d05577-c057-4cd9-a678-5a7ded4d9af8","_cell_guid":"1e80e40e-9bb1-4ba2-b14b-e5bc41232251","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-24T22:01:34.831106Z","iopub.execute_input":"2025-01-24T22:01:34.831720Z","iopub.status.idle":"2025-01-24T22:01:36.478601Z","shell.execute_reply.started":"2025-01-24T22:01:34.831683Z","shell.execute_reply":"2025-01-24T22:01:36.477797Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://e0884f79e153243ea1.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://e0884f79e153243ea1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b387c9587eca488b8e77f6f49e1a3a90"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/gradio/queueing.py\", line 625, in process_events\n    response = await route_utils.call_process_api(\n  File \"/opt/conda/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n  File \"/opt/conda/lib/python3.10/site-packages/gradio/blocks.py\", line 2044, in process_api\n    result = await self.call_function(\n  File \"/opt/conda/lib/python3.10/site-packages/gradio/blocks.py\", line 1591, in call_function\n    prediction = await anyio.to_thread.run_sync(  # type: ignore\n  File \"/opt/conda/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2177, in run_sync_in_worker_thread\n    return await future\n  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 859, in run\n    result = context.run(func, *args)\n  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 883, in wrapper\n    response = f(*args, **kwargs)\n  File \"/tmp/ipykernel_23/1681903527.py\", line 97, in process_image\n    caption, inputs = generate_caption(image)\n  File \"/tmp/ipykernel_23/1681903527.py\", line 2, in generate_caption\n    inputs = blip_processor(images=image, return_tensors=\"pt\").to(device)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/blip/processing_blip.py\", line 96, in __call__\n    raise ValueError(\"You have to specify either images or text.\")\nValueError: You have to specify either images or text.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08c26c6875d14f9c921a946ee33307fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"069aeb39457d419ba3065f6df6b58c9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adfbe4401e004c548b31a5b48661b870"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hf_write\")\nfrom huggingface_hub import HfApi, login\nlogin(token=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T22:31:40.448905Z","iopub.execute_input":"2024-12-18T22:31:40.449666Z","iopub.status.idle":"2024-12-18T22:31:40.721358Z","shell.execute_reply.started":"2024-12-18T22:31:40.449629Z","shell.execute_reply":"2024-12-18T22:31:40.720548Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"! gradio deploy --title 'DLASW-BLIP-SMOL-APP'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T22:34:07.035286Z","iopub.execute_input":"2024-12-18T22:34:07.035670Z","iopub.status.idle":"2024-12-18T22:34:21.313100Z","shell.execute_reply.started":"2024-12-18T22:34:07.035640Z","shell.execute_reply":"2024-12-18T22:34:21.311820Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Creating new Spaces Repo in \u001b[32m'/kaggle/working'\u001b[0m. Collecting metadata, press Enter \nto accept default value.\nEnter Gradio app file : ^C\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"app.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T23:46:21.574522Z","iopub.execute_input":"2024-12-19T23:46:21.574901Z","iopub.status.idle":"2024-12-19T23:46:21.773154Z","shell.execute_reply.started":"2024-12-19T23:46:21.574863Z","shell.execute_reply":"2024-12-19T23:46:21.771725Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m()\n","\u001b[0;31mAttributeError\u001b[0m: 'TupleNoPrint' object has no attribute 'close'"],"ename":"AttributeError","evalue":"'TupleNoPrint' object has no attribute 'close'","output_type":"error"}],"execution_count":8}]}
